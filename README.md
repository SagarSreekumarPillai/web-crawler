# ğŸŒ Sykell Web Crawler

A fullstack web application that accepts website URLs, crawls the content, and displays useful metadata like HTML version, title, link stats, heading counts, broken links, and presence of login forms.

Built as part of the **Sykell Full-Stack Developer Task**.

---

## âš™ï¸ Tech Stack

### ğŸ”¹ Frontend
- React + TypeScript
- Tailwind CSS
- React Router
- Axios
- Chart.js (or Recharts)
- Jest + React Testing Library

### ğŸ”¹ Backend
- Go (Golang) with Gin
- MySQL
- Go Modules
- net/http, goquery
- Docker (optional)

---

## ğŸš€ Features

### âœ… Core
- Add URLs for analysis
- Start/stop crawl operations
- Dashboard with paginated, sortable table
- Detail view per URL (with charts and broken link list)
- Re-run/delete bulk actions via checkboxes
- Real-time crawl status (Queued â†’ Crawling â†’ Done/Error)

### ğŸ“Š Collected Data Per URL
- HTML version
- Page title
- Number of heading tags (H1â€“H6)
- Count of internal vs. external links
- List of broken links (4xx/5xx)
- Presence of login form

---

## ğŸ§© Folder Structure

